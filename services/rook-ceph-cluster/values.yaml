operatorNamespace: rook-ceph

cephClusterSpec:
  cephVersion:
    image: quay.io/ceph/ceph:v18.2.2
  dataDirHostPath: /var/lib/rook
  mon:
    count: 3
    allowMultiplePerNode: false
  dashboard:
    enabled: true
  network:
    provider: host
    addressRanges:
      public:
        - "10.15.15.0/24"
      cluster:
        - "10.15.15.0/24"

  storage:
    useAllNodes: false
    useAllDevices: false
    nodes:
      - name: the-toy-factory
        devices: []
        devices:
          - name: /dev/disk/by-id/wwn-0x5000039d78c8b66e # Toshiba 8TB
            config:
              metadataDevice: /dev/disk/by-id/nvme-eui.000000000000000100a0752249f0f8de-part1 # Micron 2TB cache partition

          - name: /dev/disk/by-id/wwn-0x5000039d78c8c98c # Toshiba 8TB
            config:
              metadataDevice: /dev/disk/by-id/nvme-eui.000000000000000100a0752249f0f8de-part2 # Micron 2TB cache partition

          - name: /dev/disk/by-id/nvme-eui.000000000000000100a0752249f0f8de-part3 # Micron 2TB data partition
# cephBlockPools:
#   - name: ssd-pool
#     spec:
#       failureDomain: osd
#       replicated:
#         size: 3
#       crushRoot: default
#       deviceClass: ssd
#     storageClass:
#       enabled: true
#       name: rook-ceph-ssd
#       isDefault: false
#       reclaimPolicy: Delete
#       allowVolumeExpansion: true
#       volumeBindingMode: Immediate

#   - name: hdd-pool
#     spec:
#       failureDomain: osd
#       replicated:
#         size: 3
#       crushRoot: default
#       deviceClass: hdd
#     storageClass:
#       enabled: true
#       name: rook-ceph-hdd
#       isDefault: true  # You can choose which to be default
#       reclaimPolicy: Delete
#       allowVolumeExpansion: true
#       volumeBindingMode: Immediate
